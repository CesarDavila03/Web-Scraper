<h1>Web Scraper</h1>

<h2>Description</h2>
<p>This project demonstrates how to scrape data from a Wikipedia page that lists the largest companies in the United States by revenue. The data is extracted using BeautifulSoup, processed with Pandas, and then saved into a CSV file. This project showcases basic web scraping techniques, data extraction, and data manipulation.
</p>

<h2>Features</h2>

- <b>Scrapes data from a specified Wikipedia page.</b> 
- <b>Extracts table data and processes it into a structured format.</b>
- <b>Converts the extracted data into a Pandas DataFrame.</b> 
- <b>Saves the DataFrame as a CSV file for further analysis or use.</b>

<h2>How to Use</h2>

1. <b>Ensure you have Python and the required libraries installed.</b>
2. <b>Run the provided script to scrape data from the specified URL.</b>
3. <b>The script will save the extracted data as Companies.csv in the specified directory.</b>

<h2>Code Overview</h2>

<b>The main components of the web scraping project are:</b>
- <b>Requests: Retrieves the HTML content from the specified URL.</b>
- <b>BeautifulSoup: Parses the HTML content to extract the relevant table data.</b>
- <b>Pandas: Processes the extracted data and saves it into a CSV file.</b>

<h2>Languages and Libraries Used</h2>

- <b>Python</b> 
- <b>'requests': For making HTTP requests to fetch web pages.</b>
- <b>'BeautifulSoup4': For parsing HTML content and extracting data.</b>
- <b>'pandas': For data manipulation and saving data into a CSV file.</b>

<h2>Environments Used </h2>

- <b>macOS: Ventura 13.0</b>
